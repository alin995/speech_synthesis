# 语音合成学习（十五）学习笔记

---
## 如何利用sadtalker生成ai alin



### No.1 基于韵律建模的 SAM-BERT 

近几年，语音合成技术发展迅速，虽然合成语音的效果也在逐步提升，但是合成语音在韵律（一般指的是音调起伏、能量起伏和语速变化等）自然度上和真人还有明显差距。

学术界中，提升韵律的方法有很多，韵律建模是经过验证比较有效的方法。**韵律建模就是使得模型能够提取或者预测出韵律表征**，它可以大致地被分为两类：显式韵律建模和隐式韵律建模。显式韵律建模和隐式韵律建模的区别主要在于韵律表征是否具有实际的物理意义。



音频也有类似的音质分级，这个**采样率是决定音质的一个重要指标**，常用的采样率有：8k、16k、22.05k、24k、44.1k 和 48k 等。48k 音频的听感体验，就好比 4K 视频带来的震撼享受。本文这里，高清语音合成专指采样率为 **48kHz** 的语音合成。 

高采样率对于模型的建模能力要求更高，包括声学模型和声码器。对于声学模型，我们采用 SAM-BERT，通过实验验证，SAM-BERT 的建模能力完全满足 48k 的语音合成。因此，高清语音合成部分的探索主要集中在声码器。

对于大部分云端语音合成，由于基于神经网络的声码器的高音质的优点，它已经成为了标配。主流的神经网络声码器可以大致分为两类：自回归和非自回归的声码器。自回归的声码器有：WaveNet、WaveRNN 和 LPCNet 等；非自回归的声码器有：Flow-based、GAN-based、DPM-based 等。

在进行高清语音合成探索之前，综合性能、效果和稳定性，在8k和16k的场景下，采用 LPCNet 作为神经网络声码器。在当时，考虑直接在 LPCNet 上合成48k的声音，但是通过论文调研和一些初步的实验发现，LPCNet 存在比较大的局限性：

1. 基于线性预测系数（Linear Prediction Coefficient, LPC）假设，推广能力不足；

2. 基于逐点的交叉熵（Cross Entropy, CE）损失函数，在非语音部分不合理；

3. 基于自回归的声码器，性能差。

所以，参考学术界的研究进展采用了一种基于 GAN 的框架，它主要有三个特点：

1. 利用判别器（D）来指导声码器 (即生成器G) 的训练；2. 基于 MSD 和 MPD 建模语音中信号的平稳特性和周期特性，相比于 CE loss，能够达到对声音更好的还原效果；

2. **本文主要介绍了摩院第五代语音合成技术——基于韵律建模的 SAM-BERT、情感语音合成 Emotion TTS 和高清语音合成 HiFi-TTS 的 Expressive-TTS。

---

## 相关资源

> [语音合成-中文-kantts-公开数据集](https://modelscope.cn/datasets/speech_tts/speech_kantts_opendata/summary)

