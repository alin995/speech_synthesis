# 语音合成学习（十五）学习笔记

---

## 摩院第五代语音合成技术——基于韵律建模的 SAM-BERT、情感语音合成 Emotion TTS 和高清语音合成 HiFi-TTS 的 Expressive-TTS。



### No.1 基于韵律建模的 SAM-BERT 

近几年，语音合成技术发展迅速，虽然合成语音的效果也在逐步提升，但是合成语音在韵律（一般指的是音调起伏、能量起伏和语速变化等）自然度上和真人还有明显差距。

学术界中，提升韵律的方法有很多，韵律建模是经过验证比较有效的方法。**韵律建模就是使得模型能够提取或者预测出韵律表征**，它可以大致地被分为两类：显式韵律建模和隐式韵律建模。显式韵律建模和隐式韵律建模的区别主要在于韵律表征是否具有实际的物理意义。

在显式韵律建模中，建模的韵律表征主要指一些有实际物理意义的韵律表征，例如：基频、能量和时长，这些韵律表征可以基于信号的知识直接提取；在隐式韵律建模中，建模的韵律表征一般需要通过构建额外的提取器来获得，提取的韵律表征没有实际的物理意义，是一种隐式表征。



显式韵律建模代表性的工作是2020年被提出的 FastSpeech2，它通过引入Variance Adaptor分别对基频（pitch）、能量（energy）和时长（duration）三种韵律表征进行显式建模，一定程度上克服了TTS的one-to-many问题，显著提升了合成语音的表现力。以此为基础，学术界、工业界开始进行更深入的显式韵律建模分析优化工作。如何提升显式韵律建模的鲁棒性，怎样建模不同韵律表征间的关联关系以及如何流式生成等问题成为新的热点。



为此，我们开展了韵律建模的改造以及 Decoder 的设计，形成了阿里**基于显式韵律建模的声学模型 SAM-BERT**。1. 音素级别的基频和能量，先预测韵律轮廓，再通过 Decoder 进行细粒度建模，使得整体合成声音更加稳定；2. 时长预测与基频和能量相关联，并采用自回归的结构，使得合成声音的韵律更加自然流畅；3. 采用 PNCA AR-Decoder，支持 CPU 流式实时合成；

4. Encoder 部分用 BERT 进行初始化，引入更多的文本信息，提升合成韵律。

   ![image-20230728143023404](/Users/wangwenlin/Desktop/img/01-ecoder.png)

![image-20230728143246585](/Users/wangwenlin/Desktop/img/02-speaker.png)

针对显式韵律建模的问题，还有一种高表现力的**隐式韵律建模声学模型（ProsoSpeech）**，它采用量化隐藏韵律矢量（latent prosody vectors, LPV）来表示韵律，然后通过预训练模型来对韵律进行建模，预训练期间采用了大量低质量的语音识别数据。

![image-20230728143426594](/Users/wangwenlin/Desktop/img/03-lpv.png)

### No.2 情感语音合成 Emotional TTS 

情感语音合成指的是给定同一句话，发音人可以合成**不同情感**的语音，例如，开心、悲伤、兴奋和激动等。数据驱动是最直接也是最有效的方式，在 speaker embedding 基础上，我们加入 emotion embedding 对情感进行向量表示。同时，我们还引入细粒度控制能力，通过对**停顿、时长、基频和能量**的细粒度控制，使得合成的情感声音更具表现力。

![image-20230728143513851](/Users/wangwenlin/Desktop/img/05-emtts.png)

### No.3 高清语音合成 HiFi-TTS 

什么是高清语音合成？以视频为例，市面上的视频平台都有以下画质选项：360P、480P、720P、1080P、2K 和 4K 等，随着数字增加，视频的清晰度越高。

音频也有类似的音质分级，这个**采样率是决定音质的一个重要指标**，常用的采样率有：8k、16k、22.05k、24k、44.1k 和 48k 等。48k 音频的听感体验，就好比 4K 视频带来的震撼享受。本文这里，高清语音合成专指采样率为 **48kHz** 的语音合成。

高采样率对于模型的建模能力要求更高，包括声学模型和声码器。对于声学模型，我们采用 SAM-BERT，通过实验验证，SAM-BERT 的建模能力完全满足 48k 的语音合成。因此，高清语音合成部分的探索主要集中在声码器。

对于大部分云端语音合成，由于基于神经网络的声码器的高音质的优点，它已经成为了标配。主流的神经网络声码器可以大致分为两类：自回归和非自回归的声码器。自回归的声码器有：WaveNet、WaveRNN 和 LPCNet 等；非自回归的声码器有：Flow-based、GAN-based、DPM-based 等。

在进行高清语音合成探索之前，综合性能、效果和稳定性，在8k和16k的场景下，采用 LPCNet 作为神经网络声码器。在当时，考虑直接在 LPCNet 上合成48k的声音，但是通过论文调研和一些初步的实验发现，LPCNet 存在比较大的局限性：

1. 基于线性预测系数（Linear Prediction Coefficient, LPC）假设，推广能力不足；

2. 基于逐点的交叉熵（Cross Entropy, CE）损失函数，在非语音部分不合理；

3. 基于自回归的声码器，性能差。

所以，参考学术界的研究进展采用了一种基于 GAN 的框架，它主要有三个特点：

1. 利用判别器（D）来指导声码器 (即生成器G) 的训练；2. 基于 MSD 和 MPD 建模语音中信号的平稳特性和周期特性，相比于 CE loss，能够达到对声音更好的还原效果；

3. 对生成器和判别器的结构进行相应改造，使其在48k采样率下有更稳定的合成效果。

   ![image-20230728143640883](/Users/wangwenlin/Desktop/img/06-hifi.png)

---



---





---

**本文主要介绍了摩院第五代语音合成技术——基于韵律建模的 SAM-BERT、情感语音合成 Emotion TTS 和高清语音合成 HiFi-TTS 的 Expressive-TTS。

---

## 相关资源

> [语音合成-中文-kantts-公开数据集](https://modelscope.cn/datasets/speech_tts/speech_kantts_opendata/summary)

